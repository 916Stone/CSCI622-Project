[![Open in Visual Studio Code](https://classroom.github.com/assets/open-in-vscode-718a45dd9cf7e7f842a935f5ebbe5719a5e09af4491e668f4dbf3b35d5cca122.svg)](https://classroom.github.com/online_ide?assignment_repo_id=12482770&assignment_repo_type=AssignmentRepo)
# CSCI 622 Project

## Introduction
The rapid growth of the Internet of Things (IoT) and the Industrial IoT (IIoT) is revolutionizing everyday life and industrial operations through increased interconnectivity and automation. This evolution brings not only enhancements in efficiency and utility but also significant cybersecurity risks. The rapid growth of IoT devices, ranging from consumer gadgets to crutial industrial controls, has created cyber threats, particularly IoT malware. These threats pose serious risks, capable of disrupting everything from personal devices to critical infrastructure.

#### Business Problem 
The primary challenge in IoT cybersecurity arises from the diverse and widespread nature of IoT devices. Many of these devices, especially in industrial settings, prioritize functionality over security, rendering them vulnerable to various cyber threats. For example, the Mirai botnet malware exploited default passwords in Linux-based IoT devices for propagation. The heterogeneity and omnipresence of IoT devices complicate the detection of such malware, making it an urgent concern. A breach in IoT security can result in severe consequences, including personal data exposure and large-scale disruptions in essential services and infrastructure.

#### Business Solution 
To combat IoT malware threats, the deployment of unsupervised learning techniques offers a promising solution. In contrast to traditional methods that rely on labeled data, unsupervised learning utilizes the vast amounts of unlabeled data generated by IoT devices during their routine operations. This approach is particularly fitting for the IoT environment, where labeling data for supervised learning is impractical due to the volume and diversity of data, as well as the dynamic nature of IoT networks and evolving malware tactics. Unsupervised learning adapts to real-time data changes and trends, providing a more agile and effective means of detecting IoT malware and safeguarding the integrity and security of IoT infrastructures. The analyttic results can be found in the analytic section at the end.

## Overview
This project aims to implement data engineering techniques for the real-time malware detection system for a better management of the data including the automation of data ingestion, transformation, and serving for analytics. The project also aims to design with a robust and scalable architecture to efficiently process, analyze, and detect potential threats in IoT networks. The architecture is composed of several interconnected components, each serving a specific function in the malware detection process.

#### Technical Architecture
- Data Ingestion
- Data Lake Storage
- Data Processing and Transformation
- Data Serving
- Data Orchestration
- Data analytics
<div align="center">
  <img src="/SupplementaryInfo/archetecture.png" alt="Technical Architecture">
  <br>
  High Level Architectur
</div>


#### Technical Choices
- Azure Data Lake Storage
- Azure Databricks & PySpark
- Azure Data Factory
- Anaconda environemnt & scikit-learn packages for ML
I chose to do the machine learning locally becasue I am more familiar with it than doing it on PySpark, but eventrually it might be better to move it to cloud for better process management and maybe more hardware capabilities. For now I use Azure Data Factory for Orchestration because this project is based on the Azure enviorment, it is easier to intergrate with other services. In the future, it might be better to switch or use other ochestration tools such as AirFlow along with Data Factory.

## Roadmap
#### Current Status
- The project is currently completed with the data ingestion, transformation, and analytics(machine learning). A simple orchestration pipline has been created.

#### Future Plans
- More automation with data orchestration for not only transformation but the entire process.
- Serve streaming data to simulate real world environment.
- Integrate ML to cloud host.
- Test a compeletely different data.
- Dashboard for observability.

## Instruction
- All scripts are under scr folder, and the ingestion scripts that are under src/ingestion are hosted locally, except the EDA script is hosted on Azue Databricks, feel free to take a peak at the datasets after ingestion if you wish, but it is not necessary. Make sure you run the create_dir.py first to create the container and directory if hasn't done before, and then you can run Dataset1.py, Dataset2.py, and Dataset3.py, the order of running these 3 scripts does not matter.
- Transformation scripts that are under src/transformation are all hosted on Azure Databricks. The order to run the scripts are MergeDatasets, DataCleaning, FeatureEngineering, and Encoding. Notice that these scripts could take a while to run, especially the DataCleaning, and Encoding scipts. The first one could take more than 20 mins to run, and the Encoding script, if you do wish to run it, I highly recommend comment out the final validation section and remove coalesce(1) from the saving code, otherwise it could take hours to run. However, removing coalesce(1) will cause problems for serving because I am doing machine learning locally, so I need a whole csv instead of pieces to read.
- The machine learing notebook is located in the src/analytics folder, it is also hosted locally.
- The src/orchestration contains the artifacts from Azure Data Factory, more detials are explained in the later section about orcehstration.

## Ingestion
#### Data Source

There are two dataset used in this project. The first one is the IoT-23 dataset which belongs to Aposemat project funded by Avast. The data is provided by a sister project with this one called Malware Capture Facility Project. This project is responsible for making the long-term malware captures. They continually obtained malware and normal data to feed the Stratosphere IPS. The other dataset is called Edge-IIoTset which is a new comprehensive realistic cyber security dataset of IoT and IIoT applications on Kaggel. More details about the datasets can be found in the EDA notebook under src/ingestion, and more infomation will be explained in the transformation section. 

#### Ingestion Method

The datasets are ingested to Azure storage account usnig Python script. Both dataset are being processed so that can be directly read as a dataframe. The Edge-IIoTset dataset is on Kaggel, so the Kaggel API can be used to download this dataset. The Malware on IoT dataset does not provide an API but is can be downloaded using wget package in Python directly from the hosted website, the dataset can also be refreshed by running teh Python script.

#### Data Storage

Both dataset are ingested and stored on the Azure storage account that has been created for this project. And more processed files will also be stored in this container under the same storage account.

## Transformation, Serving, and Observability
#### Transformation
I used multiple scripts as mentioned before to transform the data in a modular way, each script contains error handling and data validation code. And the file saves to a new csv in adls at the end of each script, so if there are some issues, you can just restart one script instead of the entire process which is really helpful. 
<br>
In the current stage of the project, I ingested anoter subset of the IoT-23 dataset, so it brings a different kind of malware to it. The Edge IIotset is not used for transformation and analytics because the columns are way too different than the IoT-23 dataset. The purpose of bringing the IIot dataset is to test if a model trained with normal IoT data can be robust for IIoT, however, I tried to transform it but it would take too much time. I used 2 subsets which represents 2 different kinds of malware, so that I can test the robustness of the model. 
<br>
Mirai and Okiru are the 2 different kinds of malware, and for the merged dataset, there are 13,642,434 samples of Mirai, 11,378,759 samples for Okiru. and a total of 78,617 benign samples. And there are 21 columns in the original dataset including the label column, and the rest columns contain both categorical features such as IP address, protocal type, and numerical features such as the byte counts, packet counts as the below table shows. 

<div align="center">
  
| Field Name  | Data Type      | Nullable |
|-------------|----------------|----------|
| ts          | DoubleType     | True     |
| uid         | StringType     | True     |
| idOrigH     | StringType     | True     |
| idOrigPort  | IntegerType    | True     |
| idRespH     | StringType     | True     |
| idRespPort  | IntegerType    | True     |
| proto       | StringType     | True     |
| service     | StringType     | True     |
| duration    | DoubleType     | True     |
| origBytes   | IntegerType    | True     |
| respBytes   | IntegerType    | True     |
| connState   | StringType     | True     |
| localOrig   | StringType     | True     |
| localResp   | StringType     | True     |
| missedBytes | IntegerType    | True     |
| history     | StringType     | True     |
| origPkts    | IntegerType    | True     |
| origIpBytes | IntegerType    | True     |
| respPkts    | IntegerType    | True     |
| respIpBytes | IntegerType    | True     |
| label       | IntegerType    | True     |

</div>

Among these columns, column 'localOrig' and 'localResp' has one vlaue for the entire column, and column 'service' contains more than 90% missing value. so these columns will be removed. And since the goal is for positive training, so I have also checked the missing values just for the benign samples, and column 'duration', 'origBytes', and 'respBytes'contains more than 80% missing values for all benign samples, so these columns are also removed. 
<br>
In the rest categorical columns, there are 'proto' which is the protocal type, 'idOrigPort' and 'idRespPort' which are port number, 'idOrigH' and 'idRespH' for IP address, and finally 'connState' and 'history' which will be explained in this section later. Except the protocal type which only has 3 different values, so it can be easily encoded without worring too much about dimention increase, the rest categorical columns need to be transformed before one-hot encoding. 
<br>
For the port number, I basically categorized the numbers into 4 types which are well-known ports (0-1023), registered ports (1024-49151), dynamic/private ports (49152-65535), and the rest unkown type. Luckly, there are noo any unkown port numbers in both column. Abd for the IP address, directly split the IP into 4 numbers are proven to be the most effictive way comparing to direct one-hot encoding, or label encoding. Plus, I have too many different IP addresses, so it's also not possible to direct one-hot encode them. One thing to be noticed is that there might be IPv6 address which has a different format, but becuase for cases like IoT malware detection, there won't be too much of these, so removing IPv6 rows could be a easy way. But just in case, instead of removing those, I conveted all IPv6 address to 0.0.0.0 before spliting.
<br>
Columns 'connState' and 'history' are a bit tricky to transform, and requires some field knowledge. The basic idea of transforming these 2 columns are combining labels, and the aim is to get the labels down to 5 for both columns. 'connState' is the connection state of the sample, which contains the following labels as the following table shows. There is a limited amount of labels but it's still too much for encoding. Based on what their represents and their frequencies, I have combined all labels that contain RST to a new label, and all labels that contains SH to a new label, then I also combined SF to label S0. After these combination, I get five labels left which are, RST, S0, OTH, REJ, and N, N is for the missing values, but in this case, there aren't many and they could also mean something.

<div align="center">
  
| State Code | Description |
|------------|-------------|
| S0         | Connection attempt seen, no reply. |
| S1         | Connection established, not terminated. |
| SF         | Normal establishment and termination. Note that this is the same symbol as for state S1. You can tell the two apart because for S1 there will not be any byte counts in the summary, while for SF there will be. |
| REJ        | Connection attempt rejected. |
| S2         | Connection established and close attempt by originator seen (but no reply from responder). |
| S3         | Connection established and close attempt by responder seen (but no reply from originator). |
| RSTO       | Connection established, originator aborted (sent a RST). |
| RSTR       | Responder sent a RST. |
| RSTOS0     | Originator sent a SYN followed by a RST, we never saw a SYN-ACK from the responder. |
| RSTRH      | Responder sent a SYN ACK followed by a RST, we never saw a SYN from the (purported) originator. |
| SH         | Originator sent a SYN followed by a FIN, we never saw a SYN ACK from the responder (hence the connection was “half” open). |
| SHR        | Responder sent a SYN ACK followed by a FIN, we never saw a SYN from the originator. |
| OTH        | No SYN seen, just midstream traffic (one example of this is a “partial connection” that was not later closed). |

</div>

'history' is the hardest one to process. The value of this column is a random string, of the combination of the letters from the following table, and each letter could be either uppercase or lowercase, so technically there are unlimit amount of possibilities. However, in this project, the top 5 appearanced labels is more than 99% of the entire column. In this case, a top one-hot encoding could be used, which means, encode all the labels and only use the top ones, could be top 5 or top 10 depending on context. However, I do not wish to remove any possible infomation for robustness, so I choose to analysis the labels and combine them based on the letters. If the event comes from the originator, the letter is in upper-case; if it comes from the responder, it’s in lower-case. The ‘a’, ‘d’, ‘i’ and ‘q’ flags are recorded a maximum of one time in either direction regardless of how many are actually seen. ‘f’, ‘h’, ‘r’ and ‘s’ can be recorded multiple times for either direction if the associated sequence number differs from the last-seen packet of the same flag type. ‘c’, ‘g’, ‘t’ and ‘w’ are recorded in a logarithmic fashion: the second instance represents that the event was seen (at least) 10 times; the third instance, 100 times; etc. For examples, letter s, a, d, f offten represents a benign behavior, and r, i, q, ^ for both upper and lower cases often reprsents a malicious behavior. Thus, I decided to combine labels that contains these letters of the label itself has lower than 1% frequency. And because the positive traning is done mostly on benign samples, I combine labels based on benign letters first, and after the first round, if the label is still more than 5, then the 2nd round of combination will be based on malicious letters. And after both round, the lables could still be more than 5 because there are ambigious letters. For example, in this project, there are still 11 labels left. So, I have a finally combination based on frequencies, I have a list of frequencies from 0.01% to 0.5%, a function will be combining the lables according to if they belong to benign letters or malicious letters if they have lower than these list of frequencies until there are no more than 5 labels, the list of frequnecy can be adjust to have more tolorance, for example 1% or even 5%, and the stop condition can also be adjusted accordingly. 

<div align="center">
  
| Letter | Meaning |
|--------|---------|
| s      | a SYN w/o the ACK bit set |
| h      | a SYN+ACK (“handshake”) |
| a      | a pure ACK |
| d      | packet with payload (“data”) |
| f      | packet with FIN bit set |
| r      | packet with RST bit set |
| c      | packet with a bad checksum (applies to UDP too) |
| g      | a content gap |
| t      | packet with retransmitted payload |
| w      | packet with a zero window advertisement |
| i      | inconsistent packet (e.g. FIN+RST bits set) |
| q      | multi-flag packet (SYN+FIN or SYN+RST bits set) |
| ^      | connection direction was flipped by Zeek’s heuristic |

</div>

<br>
All the above transformation process can also be viewed in the transformation notebook scripts under src/transformation.

#### Serving
At the end of the transformation, there are validation steps to make sure there are not missing values and all columns are integer, as the following table shows, duplicates are also removed. And for serving, I wirte the transformed data as a single csv file instead of pieces to adls, however, I couldn't successfully download this PySpark structured csv file from adls in local notebook, so I ended up manually download the file for analytics. If you wish to run the machine learning notebook using this data, you could use the below link to access the served data since github does not allow me to upload large file.
<br>
https://drive.google.com/file/d/1aof3DXEqge8GNK5QTSqXCGqy0oaeut1g/view?usp=sharing

<div align="center">

| Column Name               | Datatype |
|---------------------------|----------|
| label                     | integer  |
| missedBytes               | integer  |
| origPkts                  | integer  |
| origIpBytes               | integer  |
| respPkts                  | integer  |
| respIpBytes               | integer  |
| idOrigH_1                 | integer  |
| idOrigH_2                 | integer  |
| idOrigH_3                 | integer  |
| idOrigH_4                 | integer  |
| idRespH_1                 | integer  |
| idRespH_2                 | integer  |
| idRespH_3                 | integer  |
| idRespH_4                 | integer  |
| idOrigPort_category_0     | integer  |
| idOrigPort_category_1     | integer  |
| idRespPort_category_0     | integer  |
| idRespPort_category_1     | integer  |
| proto_category_0          | integer  |
| proto_category_1          | integer  |
| connState_category_0      | integer  |
| connState_category_1      | integer  |
| connState_category_2      | integer  |
| connState_category_3      | integer  |
| history_category_0        | integer  |
| history_category_1        | integer  |
| history_category_2        | integer  |
| history_category_3        | integer  |

</div>


#### Observability
At first, I planned to link the Databricks with Azure Monitor, but I spend a long time still couldn't figure out the correct way of sending the logs from Databricks to Monitor. So, for this part I ended up using the provided observability on Databricks such as the metric of the compute cluster and sparkUI. I left some evidence in the SupplementaryInfo folder.

## Orchestration
I used Azure Data Factory for a simple orchestrion of the transformation process. Because setting up Azure Data Factory requires connection to github and I do not have access to link the classroom repo, so I linked my own repo and copied the artifacts to the src/orchestration folder just for evidence. I have successfully connected to my Azure Databricks Workspace and validated the pipeline, but I am not sure if it still works after direct copy paste.

## Analytics & Conclusion
The served data contains 3 different labels which are 0, 1, 2 for benign, mirai, and okiru. Before training the model, the dataset will be split by labels. For mixed learning, 80% of the benign data combined with a selected malicious samples from mirai will form a 10:1 ratio for bening and micious sample for the training set. And for positive learning the traning set will only contain the 80% benign sample. The testsets are the same for both method, which is the 20% benign samples with the same amount of milicious samples from both malware sets to have a 1:1 benign and malicious ratio. And because the positive learning acheieved the best results and it is also the goal of this project, so I will only show the results for positive learning to avoid getting this part too long. 
High recall is the focuse for the current stage, which means catch as much as malware possible with an acceptable loss in precision, the models will also be tunned based on high recall score. Below table shows the results for the one-class SVM model. It has acheieved a 100% recall, and 73% precision, which is not bad but can be better. And becasue the nature of SVM, when using non-linear kernels, it could gets really slow especially for data like this that has high dimention and relatively large.

<div align="center">

|           | Precision | Recall | F1-Score |
|-----------|-----------|--------|----------|
| -1        | 0.73      | 1.00   | 0.84     |
| 1         | 1.00      | 0.62   | 0.77     |
| Accuracy  |           |        | 0.81     |
| Macro Avg | 0.86      | 0.81   | 0.81     |
| Weighted Avg | 0.86   | 0.81   | 0.81     |

Mirai

</div>

<div align="center">

|           | Precision | Recall | F1-Score |
|-----------|-----------|--------|----------|
| -1        | 0.73      | 1.00   | 0.84     |
| 1         | 1.00      | 0.62   | 0.77     |
| Accuracy  |           |        | 0.81     |
| Macro Avg | 0.86      | 0.81   | 0.81     |
| Weighted Avg | 0.86   | 0.81   | 0.81     |

Okiru

</div>

Isolation forest however, is my favorite algorithm for annomaly detection problems except auto encoder. It trains really fast regradless of the dimention of the model, so with that, it would be way easier to tune compared to SVM. Below are the confusion matrix for both testset with contamination=0.1, and both achieved oerfect or nearly perfect for both recall and precision which is very surprising. 

<div align="center">
  <img src="/SupplementaryInfo/Mirai_matrix.png" alt="Mirai Matrix">
  <br>
  Mirai
</div>
<br>
<div align="center">
  <img src="/SupplementaryInfo/Okiru_matrix.png" alt="Okiru Matrix">
  <br>
  Okiru
</div>

Overall, this project is just a start and there is a lot can be improved. The current data used are still collected from a simulated environment, and both malwares are BotNet which as a lot of similarity. But I would say it's a good start especially consider the resultss, and it does achieved the goal which is to prove that only use positive data for traning is worth trying. On the data engineering perspective, I have learned a lot about the benifits and necessity of the data engineering techniques can bring to this project. I plan to keep working on this project, and focusing on orchestration and dealing with streaming data. And I believe it will be very useful in the future.

